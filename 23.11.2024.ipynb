{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('/Users/onature/Desktop/FALL-2024/MATH482/LAeq_fulltrain.csv')\n",
    "val_size = int(18399*0.2)\n",
    "train = data[:-val_size].copy()\n",
    "val = data[-val_size:].copy()\n",
    "\n",
    "X_train = train.drop(columns='class')\n",
    "y_train = train['class']\n",
    "X_val = val.drop(columns='class')\n",
    "y_val = val['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onature/miniconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='class').values\n",
    "y_train = train['class'].values - 1  # Adjust classes to be 0-based\n",
    "X_val = val.drop(columns='class').values\n",
    "y_val = val['class'].values - 1  # Adjust classes to be 0-based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 179276.4688, Val Loss: 1131143.7500, Train Acc: 0.0141, Val Acc: 0.2128\n",
      "Epoch [2/100], Loss: 740258.3125, Val Loss: 2334450.5000, Train Acc: 0.3289, Val Acc: 0.2256\n",
      "Epoch [3/100], Loss: 2563867.2500, Val Loss: 3358391.2500, Train Acc: 0.2241, Val Acc: 0.2639\n",
      "Epoch [4/100], Loss: 3445201.5000, Val Loss: 3121384.7500, Train Acc: 0.1880, Val Acc: 0.0834\n",
      "Epoch [5/100], Loss: 2623905.7500, Val Loss: 3260408.5000, Train Acc: 0.1679, Val Acc: 0.2128\n",
      "Epoch [6/100], Loss: 2767578.0000, Val Loss: 3001300.5000, Train Acc: 0.3289, Val Acc: 0.1577\n",
      "Epoch [7/100], Loss: 3148888.2500, Val Loss: 3284199.2500, Train Acc: 0.0870, Val Acc: 0.2256\n",
      "Epoch [8/100], Loss: 2809777.2500, Val Loss: 3151414.5000, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [9/100], Loss: 2550242.2500, Val Loss: 4140678.2500, Train Acc: 0.3289, Val Acc: 0.2705\n",
      "Epoch [10/100], Loss: 4162163.2500, Val Loss: 1818240.8750, Train Acc: 0.1863, Val Acc: 0.2256\n",
      "Epoch [11/100], Loss: 1283897.0000, Val Loss: 3651525.0000, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [12/100], Loss: 2963916.0000, Val Loss: 3204642.7500, Train Acc: 0.3302, Val Acc: 0.0837\n",
      "Epoch [13/100], Loss: 3160249.0000, Val Loss: 2367669.5000, Train Acc: 0.1678, Val Acc: 0.2471\n",
      "Epoch [14/100], Loss: 2342666.2500, Val Loss: 3216534.5000, Train Acc: 0.1947, Val Acc: 0.2128\n",
      "Epoch [15/100], Loss: 2596235.7500, Val Loss: 3105040.0000, Train Acc: 0.3323, Val Acc: 0.2155\n",
      "Epoch [16/100], Loss: 3118036.2500, Val Loss: 3582008.0000, Train Acc: 0.2255, Val Acc: 0.1577\n",
      "Epoch [17/100], Loss: 3460644.0000, Val Loss: 3135238.5000, Train Acc: 0.0870, Val Acc: 0.2128\n",
      "Epoch [18/100], Loss: 2401083.7500, Val Loss: 2550685.5000, Train Acc: 0.3289, Val Acc: 0.2675\n",
      "Epoch [19/100], Loss: 2463258.0000, Val Loss: 3030055.7500, Train Acc: 0.1918, Val Acc: 0.2256\n",
      "Epoch [20/100], Loss: 2351646.0000, Val Loss: 3635612.7500, Train Acc: 0.2241, Val Acc: 0.2155\n",
      "Epoch [21/100], Loss: 2820738.5000, Val Loss: 4416689.5000, Train Acc: 0.3403, Val Acc: 0.0840\n",
      "Epoch [22/100], Loss: 4218935.5000, Val Loss: 857205.3750, Train Acc: 0.1680, Val Acc: 0.2234\n",
      "Epoch [23/100], Loss: 714136.2500, Val Loss: 3257284.2500, Train Acc: 0.1909, Val Acc: 0.2223\n",
      "Epoch [24/100], Loss: 2502178.0000, Val Loss: 4265309.5000, Train Acc: 0.3295, Val Acc: 0.2256\n",
      "Epoch [25/100], Loss: 4131188.2500, Val Loss: 2938644.2500, Train Acc: 0.2245, Val Acc: 0.1577\n",
      "Epoch [26/100], Loss: 2694946.7500, Val Loss: 3165458.5000, Train Acc: 0.0870, Val Acc: 0.2128\n",
      "Epoch [27/100], Loss: 2299726.0000, Val Loss: 2365027.2500, Train Acc: 0.3289, Val Acc: 0.0870\n",
      "Epoch [28/100], Loss: 2146839.2500, Val Loss: 2950448.5000, Train Acc: 0.1391, Val Acc: 0.2253\n",
      "Epoch [29/100], Loss: 2726189.7500, Val Loss: 3538374.5000, Train Acc: 0.2245, Val Acc: 0.2482\n",
      "Epoch [30/100], Loss: 3178799.7500, Val Loss: 5219806.5000, Train Acc: 0.2026, Val Acc: 0.2128\n",
      "Epoch [31/100], Loss: 4268607.0000, Val Loss: 1485152.6250, Train Acc: 0.3302, Val Acc: 0.2115\n",
      "Epoch [32/100], Loss: 1225687.8750, Val Loss: 3019962.5000, Train Acc: 0.2288, Val Acc: 0.2128\n",
      "Epoch [33/100], Loss: 2611064.5000, Val Loss: 2671483.2500, Train Acc: 0.3327, Val Acc: 0.2327\n",
      "Epoch [34/100], Loss: 2896447.7500, Val Loss: 2450167.2500, Train Acc: 0.1947, Val Acc: 0.1577\n",
      "Epoch [35/100], Loss: 2097242.5000, Val Loss: 3069907.5000, Train Acc: 0.0870, Val Acc: 0.2261\n",
      "Epoch [36/100], Loss: 2089584.3750, Val Loss: 3635995.0000, Train Acc: 0.3473, Val Acc: 0.0992\n",
      "Epoch [37/100], Loss: 3261464.0000, Val Loss: 4147813.2500, Train Acc: 0.1600, Val Acc: 0.2256\n",
      "Epoch [38/100], Loss: 3771082.2500, Val Loss: 2736671.5000, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [39/100], Loss: 2251001.0000, Val Loss: 3570003.2500, Train Acc: 0.3296, Val Acc: 0.2555\n",
      "Epoch [40/100], Loss: 3714429.5000, Val Loss: 2665067.2500, Train Acc: 0.1899, Val Acc: 0.2175\n",
      "Epoch [41/100], Loss: 2232863.5000, Val Loss: 3235304.5000, Train Acc: 0.2247, Val Acc: 0.2128\n",
      "Epoch [42/100], Loss: 2667968.5000, Val Loss: 2137201.2500, Train Acc: 0.3299, Val Acc: 0.0791\n",
      "Epoch [43/100], Loss: 2222198.0000, Val Loss: 1860245.5000, Train Acc: 0.1651, Val Acc: 0.2300\n",
      "Epoch [44/100], Loss: 1950819.6250, Val Loss: 2789778.7500, Train Acc: 0.1947, Val Acc: 0.2128\n",
      "Epoch [45/100], Loss: 2290006.5000, Val Loss: 3940341.7500, Train Acc: 0.3331, Val Acc: 0.2188\n",
      "Epoch [46/100], Loss: 4055812.0000, Val Loss: 3547157.0000, Train Acc: 0.2251, Val Acc: 0.1577\n",
      "Epoch [47/100], Loss: 3540325.7500, Val Loss: 2712268.7500, Train Acc: 0.0870, Val Acc: 0.2128\n",
      "Epoch [48/100], Loss: 2098541.5000, Val Loss: 2228394.0000, Train Acc: 0.3289, Val Acc: 0.2493\n",
      "Epoch [49/100], Loss: 2256981.2500, Val Loss: 3562181.5000, Train Acc: 0.2050, Val Acc: 0.2191\n",
      "Epoch [50/100], Loss: 3010862.7500, Val Loss: 3206087.5000, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [51/100], Loss: 2531533.0000, Val Loss: 3465270.0000, Train Acc: 0.3293, Val Acc: 0.0840\n",
      "Epoch [52/100], Loss: 3423475.2500, Val Loss: 1043101.1875, Train Acc: 0.1675, Val Acc: 0.2052\n",
      "Epoch [53/100], Loss: 1041601.1250, Val Loss: 2626360.2500, Train Acc: 0.2249, Val Acc: 0.2128\n",
      "Epoch [54/100], Loss: 2471500.0000, Val Loss: 3777486.0000, Train Acc: 0.3324, Val Acc: 0.2454\n",
      "Epoch [55/100], Loss: 4238664.0000, Val Loss: 3021448.2500, Train Acc: 0.1944, Val Acc: 0.1577\n",
      "Epoch [56/100], Loss: 2908946.2500, Val Loss: 2678440.7500, Train Acc: 0.0863, Val Acc: 0.2128\n",
      "Epoch [57/100], Loss: 1952363.5000, Val Loss: 2903575.0000, Train Acc: 0.3287, Val Acc: 0.2196\n",
      "Epoch [58/100], Loss: 2810296.7500, Val Loss: 2592343.5000, Train Acc: 0.2241, Val Acc: 0.1916\n",
      "Epoch [59/100], Loss: 2372129.0000, Val Loss: 2967262.7500, Train Acc: 0.2293, Val Acc: 0.2128\n",
      "Epoch [60/100], Loss: 2279431.0000, Val Loss: 3117658.2500, Train Acc: 0.3287, Val Acc: 0.0834\n",
      "Epoch [61/100], Loss: 3064088.2500, Val Loss: 2200697.5000, Train Acc: 0.1655, Val Acc: 0.2191\n",
      "Epoch [62/100], Loss: 2165285.0000, Val Loss: 2402390.0000, Train Acc: 0.2257, Val Acc: 0.2128\n",
      "Epoch [63/100], Loss: 2239538.7500, Val Loss: 3418379.5000, Train Acc: 0.3331, Val Acc: 0.2460\n",
      "Epoch [64/100], Loss: 3872560.2500, Val Loss: 2443155.0000, Train Acc: 0.1947, Val Acc: 0.1577\n",
      "Epoch [65/100], Loss: 2326331.0000, Val Loss: 2459219.7500, Train Acc: 0.0867, Val Acc: 0.2226\n",
      "Epoch [66/100], Loss: 1724090.0000, Val Loss: 3861465.7500, Train Acc: 0.3220, Val Acc: 0.2199\n",
      "Epoch [67/100], Loss: 3733317.0000, Val Loss: 2223161.0000, Train Acc: 0.2241, Val Acc: 0.1590\n",
      "Epoch [68/100], Loss: 1988781.5000, Val Loss: 2687630.2500, Train Acc: 0.2158, Val Acc: 0.2128\n",
      "Epoch [69/100], Loss: 2062279.2500, Val Loss: 2037097.8750, Train Acc: 0.3287, Val Acc: 0.2177\n",
      "Epoch [70/100], Loss: 2056737.3750, Val Loss: 2786835.2500, Train Acc: 0.2225, Val Acc: 0.0815\n",
      "Epoch [71/100], Loss: 2673481.5000, Val Loss: 2456463.0000, Train Acc: 0.1706, Val Acc: 0.2286\n",
      "Epoch [72/100], Loss: 2348826.0000, Val Loss: 4476738.5000, Train Acc: 0.2223, Val Acc: 0.2128\n",
      "Epoch [73/100], Loss: 3814526.5000, Val Loss: 1777592.2500, Train Acc: 0.3301, Val Acc: 0.1577\n",
      "Epoch [74/100], Loss: 1787564.5000, Val Loss: 2976148.5000, Train Acc: 0.0870, Val Acc: 0.2196\n",
      "Epoch [75/100], Loss: 2351199.2500, Val Loss: 4377992.5000, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [76/100], Loss: 3605677.2500, Val Loss: 2876050.0000, Train Acc: 0.3287, Val Acc: 0.2536\n",
      "Epoch [77/100], Loss: 2770588.0000, Val Loss: 2316562.2500, Train Acc: 0.1860, Val Acc: 0.2207\n",
      "Epoch [78/100], Loss: 1625231.7500, Val Loss: 3259491.2500, Train Acc: 0.3270, Val Acc: 0.2191\n",
      "Epoch [79/100], Loss: 3185421.2500, Val Loss: 4115497.7500, Train Acc: 0.2262, Val Acc: 0.0829\n",
      "Epoch [80/100], Loss: 3904321.7500, Val Loss: 1786025.0000, Train Acc: 0.1687, Val Acc: 0.2096\n",
      "Epoch [81/100], Loss: 1616629.3750, Val Loss: 2597263.2500, Train Acc: 0.3336, Val Acc: 0.2449\n",
      "Epoch [82/100], Loss: 3045165.2500, Val Loss: 2761342.0000, Train Acc: 0.1947, Val Acc: 0.2142\n",
      "Epoch [83/100], Loss: 2624344.2500, Val Loss: 2344600.7500, Train Acc: 0.2279, Val Acc: 0.1669\n",
      "Epoch [84/100], Loss: 2082563.0000, Val Loss: 2124904.7500, Train Acc: 0.2565, Val Acc: 0.1577\n",
      "Epoch [85/100], Loss: 2349391.5000, Val Loss: 2039094.5000, Train Acc: 0.0847, Val Acc: 0.0824\n",
      "Epoch [86/100], Loss: 1651913.0000, Val Loss: 2134692.5000, Train Acc: 0.1609, Val Acc: 0.2253\n",
      "Epoch [87/100], Loss: 1746389.6250, Val Loss: 3490725.5000, Train Acc: 0.3288, Val Acc: 0.2177\n",
      "Epoch [88/100], Loss: 3711680.5000, Val Loss: 4025513.0000, Train Acc: 0.1992, Val Acc: 0.2191\n",
      "Epoch [89/100], Loss: 3747873.5000, Val Loss: 2641825.7500, Train Acc: 0.2241, Val Acc: 0.2128\n",
      "Epoch [90/100], Loss: 2255100.5000, Val Loss: 2326322.7500, Train Acc: 0.3287, Val Acc: 0.2460\n",
      "Epoch [91/100], Loss: 2581876.2500, Val Loss: 2547834.2500, Train Acc: 0.1860, Val Acc: 0.2142\n",
      "Epoch [92/100], Loss: 2217453.2500, Val Loss: 3125970.0000, Train Acc: 0.2268, Val Acc: 0.2128\n",
      "Epoch [93/100], Loss: 2658975.7500, Val Loss: 2715747.7500, Train Acc: 0.3307, Val Acc: 0.0761\n",
      "Epoch [94/100], Loss: 2889066.7500, Val Loss: 1719145.7500, Train Acc: 0.1476, Val Acc: 0.1577\n",
      "Epoch [95/100], Loss: 1906049.7500, Val Loss: 2107478.5000, Train Acc: 0.0870, Val Acc: 0.2128\n",
      "Epoch [96/100], Loss: 1670550.1250, Val Loss: 3272807.2500, Train Acc: 0.3287, Val Acc: 0.1995\n",
      "Epoch [97/100], Loss: 3453152.5000, Val Loss: 1528537.3750, Train Acc: 0.2106, Val Acc: 0.2291\n",
      "Epoch [98/100], Loss: 1397799.2500, Val Loss: 2750495.5000, Train Acc: 0.2007, Val Acc: 0.1976\n",
      "Epoch [99/100], Loss: 2061828.8750, Val Loss: 4844255.5000, Train Acc: 0.2405, Val Acc: 0.2128\n",
      "Epoch [100/100], Loss: 4037807.5000, Val Loss: 1934615.7500, Train Acc: 0.3309, Val Acc: 0.0788\n",
      "Best Validation Accuracy (Logistic Regression): 0.2705\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_classes = 6\n",
    "model = LogisticRegressionModel(input_dim, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter('runs/logistic_regression_experiment')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_val_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    train_accuracy = (predicted == y_train).sum().item() / y_train.size(0)\n",
    "\n",
    "    # Log the loss and accuracy\n",
    "    writer.add_scalar('Training Loss', loss.item(), epoch)\n",
    "    writer.add_scalar('Training Accuracy', train_accuracy, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = (val_predicted == y_val).sum().item() / y_val.size(0)\n",
    "        \n",
    "        writer.add_scalar('Validation Loss', val_loss.item(), epoch)\n",
    "        writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "        # Update best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, '\n",
    "          f'Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "\n",
    "print(f'Best Validation Accuracy (Logistic Regression): {best_val_accuracy:.4f}')\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 99543.2422, Val Loss: 952213110784.0000, Train Acc: 0.0132, Val Acc: 0.2128\n",
      "Epoch [2/100], Loss: 651103371264.0000, Val Loss: 73284.4844, Train Acc: 0.3289, Val Acc: 0.0549\n",
      "Epoch [3/100], Loss: 11247.8613, Val Loss: 1.8138, Train Acc: 0.0107, Val Acc: 0.2256\n",
      "Epoch [4/100], Loss: 1.8155, Val Loss: 1.8134, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [5/100], Loss: 1.8148, Val Loss: 1.8130, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [6/100], Loss: 1.8141, Val Loss: 1.8126, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [7/100], Loss: 1.8134, Val Loss: 1.8123, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [8/100], Loss: 1.8127, Val Loss: 1.8119, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [9/100], Loss: 1.8121, Val Loss: 1.8115, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [10/100], Loss: 1.8114, Val Loss: 1.8111, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [11/100], Loss: 1.8107, Val Loss: 1.8107, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [12/100], Loss: 1.8100, Val Loss: 1.8104, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [13/100], Loss: 1.8094, Val Loss: 1.8100, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [14/100], Loss: 1.8087, Val Loss: 1.8096, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [15/100], Loss: 1.8080, Val Loss: 1.8093, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [16/100], Loss: 1.8074, Val Loss: 1.8089, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [17/100], Loss: 1.8067, Val Loss: 1.8085, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [18/100], Loss: 1.8060, Val Loss: 1.8082, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [19/100], Loss: 1.8054, Val Loss: 1.8078, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [20/100], Loss: 1.8047, Val Loss: 1.8075, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [21/100], Loss: 1.8041, Val Loss: 1.8071, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [22/100], Loss: 1.8034, Val Loss: 1.8067, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [23/100], Loss: 1.8027, Val Loss: 1.8064, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [24/100], Loss: 1.8021, Val Loss: 1.8060, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [25/100], Loss: 1.8014, Val Loss: 1.8057, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [26/100], Loss: 1.8008, Val Loss: 1.8053, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [27/100], Loss: 1.8002, Val Loss: 1.8050, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [28/100], Loss: 1.7995, Val Loss: 1.8046, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [29/100], Loss: 1.7989, Val Loss: 1.8043, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [30/100], Loss: 1.7982, Val Loss: 1.8040, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [31/100], Loss: 1.7976, Val Loss: 1.8036, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [32/100], Loss: 1.7970, Val Loss: 1.8033, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [33/100], Loss: 1.7963, Val Loss: 1.8029, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [34/100], Loss: 1.7957, Val Loss: 1.8026, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [35/100], Loss: 1.7951, Val Loss: 1.8023, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [36/100], Loss: 1.7945, Val Loss: 1.8019, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [37/100], Loss: 1.7938, Val Loss: 1.8016, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [38/100], Loss: 1.7932, Val Loss: 1.8013, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [39/100], Loss: 1.7926, Val Loss: 1.8009, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [40/100], Loss: 1.7920, Val Loss: 1.8006, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [41/100], Loss: 1.7914, Val Loss: 1.8003, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [42/100], Loss: 1.7908, Val Loss: 1.8000, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [43/100], Loss: 1.7902, Val Loss: 1.7996, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [44/100], Loss: 1.7896, Val Loss: 1.7993, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [45/100], Loss: 1.7889, Val Loss: 1.7990, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [46/100], Loss: 1.7883, Val Loss: 1.7987, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [47/100], Loss: 1.7877, Val Loss: 1.7984, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [48/100], Loss: 1.7871, Val Loss: 1.7981, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [49/100], Loss: 1.7865, Val Loss: 1.7977, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [50/100], Loss: 1.7859, Val Loss: 1.7974, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [51/100], Loss: 1.7854, Val Loss: 1.7971, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [52/100], Loss: 1.7848, Val Loss: 1.7968, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [53/100], Loss: 1.7842, Val Loss: 1.7965, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [54/100], Loss: 1.7836, Val Loss: 1.7962, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [55/100], Loss: 1.7830, Val Loss: 1.7959, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [56/100], Loss: 1.7824, Val Loss: 1.7956, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [57/100], Loss: 1.7818, Val Loss: 1.7953, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [58/100], Loss: 1.7813, Val Loss: 1.7950, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [59/100], Loss: 1.7807, Val Loss: 1.7947, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [60/100], Loss: 1.7801, Val Loss: 1.7944, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [61/100], Loss: 1.7795, Val Loss: 1.7941, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [62/100], Loss: 1.7790, Val Loss: 1.7938, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [63/100], Loss: 1.7784, Val Loss: 1.7935, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [64/100], Loss: 1.7778, Val Loss: 1.7932, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [65/100], Loss: 1.7772, Val Loss: 1.7929, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [66/100], Loss: 1.7767, Val Loss: 1.7927, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [67/100], Loss: 1.7761, Val Loss: 1.7924, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [68/100], Loss: 1.7756, Val Loss: 1.7921, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [69/100], Loss: 1.7750, Val Loss: 1.7918, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [70/100], Loss: 1.7744, Val Loss: 1.7915, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [71/100], Loss: 1.7739, Val Loss: 1.7912, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [72/100], Loss: 1.7733, Val Loss: 1.7910, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [73/100], Loss: 1.7728, Val Loss: 1.7907, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [74/100], Loss: 1.7722, Val Loss: 1.7904, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [75/100], Loss: 1.7717, Val Loss: 1.7901, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [76/100], Loss: 1.7711, Val Loss: 1.7898, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [77/100], Loss: 1.7706, Val Loss: 1.7896, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [78/100], Loss: 1.7700, Val Loss: 1.7893, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [79/100], Loss: 1.7695, Val Loss: 1.7890, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [80/100], Loss: 1.7690, Val Loss: 1.7888, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [81/100], Loss: 1.7684, Val Loss: 1.7885, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [82/100], Loss: 1.7679, Val Loss: 1.7882, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [83/100], Loss: 1.7674, Val Loss: 1.7880, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [84/100], Loss: 1.7668, Val Loss: 1.7877, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [85/100], Loss: 1.7663, Val Loss: 1.7874, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [86/100], Loss: 1.7658, Val Loss: 1.7872, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [87/100], Loss: 1.7652, Val Loss: 1.7869, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [88/100], Loss: 1.7647, Val Loss: 1.7867, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [89/100], Loss: 1.7642, Val Loss: 1.7864, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [90/100], Loss: 1.7637, Val Loss: 1.7861, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [91/100], Loss: 1.7632, Val Loss: 1.7859, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [92/100], Loss: 1.7626, Val Loss: 1.7856, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [93/100], Loss: 1.7621, Val Loss: 1.7854, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [94/100], Loss: 1.7616, Val Loss: 1.7851, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [95/100], Loss: 1.7611, Val Loss: 1.7849, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [96/100], Loss: 1.7606, Val Loss: 1.7846, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [97/100], Loss: 1.7601, Val Loss: 1.7844, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [98/100], Loss: 1.7596, Val Loss: 1.7841, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [99/100], Loss: 1.7591, Val Loss: 1.7839, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Epoch [100/100], Loss: 1.7586, Val Loss: 1.7837, Train Acc: 0.2241, Val Acc: 0.2256\n",
      "Best Validation Accuracy (MLP): 0.2256\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 64  # You can adjust the hidden layer size\n",
    "num_classes = 6\n",
    "model = MLPModel(input_dim, hidden_dim, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter('runs/mlp_experiment')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_val_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    train_accuracy = (predicted == y_train).sum().item() / y_train.size(0)\n",
    "\n",
    "    # Log the loss and accuracy\n",
    "    writer.add_scalar('Training Loss', loss.item(), epoch)\n",
    "    writer.add_scalar('Training Accuracy', train_accuracy, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = (val_predicted == y_val).sum().item() / y_val.size(0)\n",
    "        \n",
    "        writer.add_scalar('Validation Loss', val_loss.item(), epoch)\n",
    "        writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "        # Update best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, '\n",
    "          f'Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "\n",
    "print(f'Best Validation Accuracy (MLP): {best_val_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
